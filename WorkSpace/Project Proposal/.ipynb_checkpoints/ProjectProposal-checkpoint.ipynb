{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Proposal Team 7\n",
    "\n",
    "Spencer Arnold <br/>\n",
    "Ryan Hines <br/>\n",
    "Matthew Hawks <br/>\n",
    "Jacob Anderson <br/>\n",
    "Tae Kweon <br/>\n",
    "Ali Najib <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: block; float:left;\">\n",
    "    <h3>Code Def</h3>\n",
    "    \n",
    "| Acronyms | Definition                      |\n",
    "|----------|:-------------------------------:|\n",
    "| PRN      | Pseudo random number            |\n",
    "| PRNG     | Pseudo random number generator  |\n",
    "\n",
    "\n",
    "### Our Aim\n",
    "* To train a neural net to predict PRNs from a chosen PRNGs output. We aim to train new neural networks on additional methods of PRN generation, if we have enough time.\n",
    "* Our secondary aim is to continue the quest [[1]](https://arxiv.org/ftp/arxiv/papers/1801/1801.01117.pdf)[[2]](https://arxiv.org/pdf/1810.00378.pdf) for insights on pseudo randomness.\n",
    "\n",
    "### The Meat\n",
    "Our proposal is to create predictive networks that are fed outputs of PRNGs, which will attempt to predict an nth value, based on previous n-1 values in a particular set of input data. After being trained on, ideally thousands of sets, the predictive network will form a better stochastic \"understanding\" of how the PRNG works underneath, thus being able to more accurately predict numbers generated from that PRNG in the future. The backpropagation will flow through the predictive network to acheive the adversarial nature of a traditional GAN setup, but in reality, we won't be using a generative net, just a PRNG algorithm, so the generative part of our setup won't be defensive. There is an eloquent description of what our predictor network will do below.\n",
    "\n",
    "> The predictor network maximizes [gradient ascent] the probability of correctly predicting the nth value from the other [n-1] values.[ref](https://arxiv.org/pdf/1810.00378.pdf)\n",
    "\n",
    "![HERE IS OUR DESIGN DIAGRAM](ModelDiagram.png)\n",
    "\n",
    "We hope to do this process above with several PRNGs, starting with one of the oldest in 1946 and gradually making our way to newer methods of PRN generation.\n",
    "\n",
    ">[Middle-square method (1946)](https://en.wikipedia.org/wiki/Middle-square_method)<br/>\n",
    "[Lehmer generator (1951)](https://en.wikipedia.org/wiki/Lehmer_random_number_generator)<br/>\n",
    "[Linear congruential generator (1958)](https://en.wikipedia.org/wiki/Linear_congruential_generator)<br/>\n",
    "[Lagged Fibonacci (1965)](https://en.wikipedia.org/wiki/Lagged_Fibonacci_generator)<br/>\n",
    "[Wichmann-Hill generator (1982)](https://en.wikipedia.org/wiki/Wichmann%E2%80%93Hill)<br/>\n",
    "[Park-Miller generator (1988)](https://en.wikipedia.org/wiki/Lehmer_random_number_generator)<br/>\n",
    "[Maximally periodic reciprocals (1992)](https://en.wikipedia.org/wiki/Sophie_Germain_prime)<br/>\n",
    "[Mersenne Twister (1998)](https://en.wikipedia.org/wiki/Mersenne_Twister)<br/>\n",
    "\n",
    "Theoretically, we will be able to look at the data and stochastically rank each PRNG on how easy a prediction attack worked on it. This should also tell us how \"good\" each PRNG is at generating \"random\" numbers.\n",
    "\n",
    "#### *Our hypothesis comes in two parts:*\n",
    "1) We predict there will be a positive trend over time on the cryptographic strength of each subsequent PRNG, given the nature of the increasing importance of stronger PRNGs.\n",
    "\n",
    "2) We also predict that as we get into cryptographically stronger generation methods, our prediction success rates (even with learning) will be less effective.\n",
    "\n",
    "### Practical Application\n",
    "\n",
    "A GAN method similar to this could be used in the future during a real-time prediction attack scenario. If attackers are somehow able to break a strong PRNG that is used to generate numbers for cryptographic methods, a method like this could be used as a defense mechanism to prevent (or slow down) further PRN generation cycles from being compromised.\n",
    "\n",
    "Of course, determining any correlation in pseudo random sequences would be a great help to the community to write stronger generators\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amendments based on feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is an Amendment to our project proposal, reflecting on feedback. There were three large critiques that needed to be addressed. I am paraphrasing the feedback quotes.\n",
    "__________________________________________\n",
    "\n",
    "Feedback 1:\n",
    "   > The length of the set of n-values we will feed into the predictive network needs to be of concrete statistical relevance. (i.e., what is the correct choice of n and how do we     statistically prove this?).\n",
    "   \n",
    "Amendment 1:\n",
    "   > Needs more discussion\n",
    "__________________________________________\n",
    "Feedback 2:\n",
    "   > What network architectures will be employed? Having a couple of different architectures and listing the applicative advantages/disadvantages will convince everyone we didn't blindly choose a single architecture.\n",
    "   \n",
    "Amendment 2:\n",
    "   > The predictive neural net will be a similar model to [this article](https://arxiv.org/pdf/1810.00378.pdf) . . .\n",
    "   \n",
    "   > Predictive Model - The predictor is a convolutional neural network implementing the function P(rsplit) :Bn-1→Bnth where rsplit is the  generator’s output vector with the last element removed. The last element is used as the corresponding label for the predictor’s input.\n",
    "   \n",
    "__________________________________________\n",
    "\n",
    "Feedback 3:\n",
    "   > Additional hypothesis could be used regarding different n-length sets and a standard for acceptable accuracies.\n",
    "   \n",
    "Amendment 3:\n",
    "   > Adding additional hypothesis around our results with different n-length sets, as well as boundaries for acceptable accuracy.... 95%?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
